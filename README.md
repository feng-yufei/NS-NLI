# NS-NLI

# Neuro-Symbolic Natural Logic with Introspective Revision for Natural Language Inference (TACL 2022)
If help on the code is needed, contact Yufei @ feng.yufei@queensu.ca


# All required pre-processed data
To run our model and reproduce our results, please load the pkl file provided in the following link:
https://drive.google.com/file/d/1ijzuDOVF40_eMqR9VYturX_10qMHRxMi/view?usp=sharing
The zip file includes all the training data, and challenge tests

We recommend followers start with our data, since reproducing the pkl file requires stanford nlp parser and aligners, which causes many trouble for new users.

# checkpoint file provided
One of the checkpoints are provided in the following link. The checkpoint is one of the saved models being averaged in our paper's results.



## Please cite the following paper if you find our code helpful:
```
@article{feng2022neuro,
  title={Neuro-symbolic Natural Logic with Introspective Revision for Natural Language Inference},
  author={Feng, Yufei and Yang, Xiaoyu and Zhu, Xiaodan and Greenspan, Michael},
  journal={Transactions of the Association for Computational Linguistics},
  volume={10},
  pages={240--256},
  year={2022}
}
```
